### 硬件选型报告
> Kevin Q.
****
[TOC]

****
#### 概要
*本报告将在两个文献来源共26篇文章进行FPGA在神经网络硬件加速中开发板类型选型情况进行总结*<br>
其中章节[英文文献](#英文文献)和[中文文献](#中文文献)为详细情况报告,[总结](#总结)为笔者的个人看法

#### 英文文献

**1. 筛选标准**
剔除掉使用Altera和纯FPGA开发的作者，重点筛查使用Soc的情况

**2. 文献特征**
在arXiv上寻找的近两年范围内的近期前沿工作者在FPGA加速问题上器件的使用

**3. 使用情况**
+ **ZedBoard (XC7Z020): Avnet 经典 Zynq 开发板**
    文献[2]和文献[11]都使用了安富利的经典zynq开发板
    + **其中值得注意的是文献[2]是**一篇最近挂上arXiv的综述性文章,三位作者都隶属于哈利法科技大学,其中一位作者拥有Senior Member, IEEE的认可,文章全面回顾了在FPGA上部署CNN进行目标检测、分类和跟踪的最新进展,重点关注FPGA作为GPU和ASIC的强大替代品,文章深入探讨了算法创新、硬件加速技术以及剪枝、量化和稀疏感知等优化策略的集成，以在硬件约束下最大化性能。同时，还考察了现代FPGA平台（如LUT-DSP、SoC FPGA和ACAP）及其在深度学习工作负载中的能力，并审视了Vitis AI、FINN和Intel FPGA AI Suite等软件开发工具,其除了提到ZedBoard,还提及了KV260和ZCU104,这都是目前领域经常被提及和使用的开发板
+ **Zybo Z7-20 (XC7Z020): Digilent 经典入门级 Zynq 板卡**
    文献[10]和文献[11]都提及了德致伦的zybo
    + **其中文献[11]是**基于一种硬件感知剪枝方法,以结构化的方式引入稀疏性,与标准剪枝算法相比，在推理时间上实现了显著改进(在最佳情况下提高 45%),注意的是这篇文章在开发和验证阶段使用到了Zybo和ZedBoard两种开发板
+ **Ultra96-V2 (XCZU3EG): Avnet 小型 MPSoC 开发板**
    **文献[3]使用**了Ultra96,这是安富利的基于Zynq UltraScale+ MPSoC 家族3eg器件的经济化开发板,利用Xilinx Vitis AI和深度学习处理单元（DPU），部署并优化了Pixel-Net、Patch-Net、Scene-Net和U-Net四种CNN模型。通过通道剪枝和8位量化，模型在保持高精度的同时，参数和FLOPs大幅减少。图像级模型Scene-Net和U-Net实现57.14/37.45 FPS的实时推理，功耗约2.5W，显著优于现有方案
+ **Kria KV260 Vision AI Starter Kit**
    **同上文在文献[2]被提及**,Kria 是 AMD-Xilinx 推出的一个全新的产品线，它不是芯片系列,旨在简化和加速边缘 AI 和嵌入式应用的开发，提供开箱即用的硬件和软件堆栈，降低开发门槛,针对视觉和 AI 应用，提供丰富的视觉接口
+ **ZCU102 Evaluation Kit (XCZU9EG): Xilinx 官方评估套件**
    **文献[4] [6] [14] [15]都使用了**ZCU102这款Xilinx 官方评估套件作为验证开发板
    + **其中文献[4]利用**ADAPTOR加速方法在FPGA上实现Transformer注意力机制的推理加速
    + **而文献[14]提出**了一种自动化迭代滤波器剪枝方法，专门针对基于连接的CNN架构，特别是YOLOv7等目标检测器
    + **而文献[15]提出**一种FPGA上流式CNN的智能片外驱逐方法，旨在解决现代CNN因复杂连接和海量参数导致的片上内存限制。它通过激活驱逐和权重碎片化机制，策略性地将部分数据卸载至片外内存，同时不中断计算流水线。结合子图分区和设计空间探索，SMOF优化了片上/片外内存分配，支持2D/3D CNN及多种视觉任务，在吞吐量上相较现有工作提升高达10.65倍，实现领先性能
+ **ZCU104 Evaluation Kit (XCZU7EV): Xilinx 官方评估套件**
    **文献[2] [7] [8]使用**了ZCU104这款Xilinx 官方评估套件
    + **文献[7]提出**TrIM脉动阵列架构，旨在解决卷积神经网络（CNN）硬件加速中的数据移动能耗瓶颈。TrIM采用创新的三角输入移动数据流，通过将权重固定在处理单元并优化输入复用，显著减少了内存访问，比现有脉动阵列低一个数量级
    + **而文献[8]利用**Vitis-AI在Xilinx ZCU104 FPGA上加速图像分类CNN。针对CPU/GPU在吞吐量和能效方面的局限，研究团队对CIFAR-10数据集上的2D CNN进行FP32训练、INT8量化、DPU编译和部署。结果显示，与CPU/GPU基线相比，FPGA方案实现了3.33-5.82倍的吞吐量提升和3.39-6.30倍的能效提升，并采用双B4096 DPU核以300MHz运行

**4. 参考文献**

[1] CHEN B, KHAN M T, GOUSSETIS G, 等. COMET: Co-Optimization of a CNN Model using Efficient-Hardware OBC Techniques[EB/OL]. arXiv, 2025[2025-10-31]. http://arxiv.org/abs/2510.03516.<br>
[2] SALI S M, MERIBOUT M, MAJEED A A. Real Time FPGA Based CNNs for Detection, Classification, and Tracking in Autonomous Systems: State of the Art Designs and Optimizations[EB/OL]. arXiv, 2025[2025-10-31]. http://arxiv.org/abs/2509.04153.<br>
[3] CRATERE A, FARISSI M S, CARBONE A, 等. Efficient FPGA-accelerated Convolutional Neural Networks for Cloud Detection on CubeSats[J]. IEEE Journal on Miniaturization for Air and Space Systems, 2025, 6(3): 187-197.<br>
[4] KABIR E, BAKOS J D, ANDREWS D, 等. A Runtime-Adaptive Transformer Neural Network Accelerator on FPGAs[EB/OL]. arXiv, 2025[2025-10-31]. http://arxiv.org/abs/2411.18148.<br>
[5] LI R. Dataflow & Tiling Strategies in Edge-AI FPGA Accelerators: A Comprehensive Literature Review[EB/OL]. arXiv, 2025[2025-10-31]. http://arxiv.org/abs/2505.08992.<br>
[6] JIANG J, ZHOU Y, GONG Y, 等. FPGA-based Acceleration for Convolutional Neural Networks: A Comprehensive Review[EB/OL]. arXiv, 2025[2025-10-31]. http://arxiv.org/abs/2505.13461.<br>
[7] SESTITO C, AGWA S, PRODROMAKIS T. TrIM, Triangular Input Movement Systolic Array for Convolutional Neural Networks: Architecture and Hardware Implementation[J]. IEEE Transactions on Circuits and Systems I: Regular Papers, 2025, 72(5): 2263-2273.<br>
[8] LI Z, HONG F Z, YUE C P. FPGA-based Acceleration of Neural Network for Image Classification using Vitis AI[EB/OL]. arXiv, 2024[2025-10-31]. http://arxiv.org/abs/2412.20974.<br>
[9] SARKAR A. A Novel FPGA-based CNN Hardware Accelerator: Optimization for Convolutional Layers using Karatsuba Ofman Multiplier[EB/OL]. arXiv, 2024[2025-10-31]. http://arxiv.org/abs/2412.20393.<br>
[10] CAMPOS N, EDIRISINGHE E, CHESNOKOV S, 等. Fast Generation of Custom Floating-Point Spatial Filters on FPGAs[EB/OL]. arXiv, 2024[2025-10-31]. http://arxiv.org/abs/2409.05837.<br>
[11] PECCIA F N, FERREYRO L, FURFARO A. HAPM -- Hardware Aware Pruning Method for CNN hardware accelerators in resource constrained devices[EB/OL]. arXiv, 2024[2025-10-31]. http://arxiv.org/abs/2408.14055.<br>
[12] LUO Z, WU H, GE Z, 等. Real-time Event Recognition of Long-distance Distributed Vibration Sensing with Knowledge Distillation and Hardware Acceleration[EB/OL]. arXiv, 2024[2025-10-31]. http://arxiv.org/abs/2408.03647.<br>
[13] DOUMET M, STAN M, HALL M, 等. H2PIPE: High throughput CNN Inference on FPGAs with High-Bandwidth Memory[EB/OL]. arXiv, 2024[2025-10-31]. http://arxiv.org/abs/2408.09209.<br>
[14] PAVLITSKA S, BAGGE O, PECCIA F, 等. Iterative Filter Pruning for Concatenation-based CNN Architectures[EB/OL]. arXiv, 2024[2025-10-31]. http://arxiv.org/abs/2405.03715.<br>
[15] TOUPAS P, YU Z, BOUGANIS C S, 等. SMOF: Streaming Modern CNNs on FPGAs with Smart Off-Chip Eviction[EB/OL]. arXiv, 2024[2025-10-31]. http://arxiv.org/abs/2403.18921.<br>

#### 中文文献

**1. 筛选标准**
剔除掉使用Altera和纯FPGA开发的作者，重点筛查使用Soc的情况

**2. 文献特征**
为知网上针对神经网络加速器的学位论文，按被引用数排列抓取

**3. 使用情况**
+ **Pynq-Z2 (XC7Z020): TUL/Xilinx 合作，基于 Python 的 Zynq 开发板**
    只有文献[6]使用了这个器件,目标为利用循环优化和乒乓操作对数据流的并行度入手进行优化,在数据复杂度方面将32位浮点数量化为16位定点数,实现对YOLOv3-Tiny目标检测算法的加速

+ **ZC702/ZC706(XC7Z020): Xilinx 官方评估套件**
    文献[7]与文献[11]使用了Xilinx 官方评估套件,相似的也是以流水线并行为主,定点化低精度运算为辅实现对YOLO算法的加速

+ **ZedBoard (XC7Z020): Avnet 经典 Zynq 开发板**
    文献[5]和[9]使用了安富利的ZedBoard,涉及了定点化,乒乓操作等经典算法,并实现了使用脉动阵列对乘累加运算进行加速

+ **ZCU102(XCZU9EG): Xilinx 官方评估套件**
    文献[2]使用了ZCU102,选择SqueezeNet作为CNN设计的基础,利用卷积核替换,去除冗余Padding等减负的方法实现对CNN的加速

**4. 参考文献**

[1] 王思阳. 基于FPGA的卷积神经网络加速器设计[D/OL]. 电子科技大学, 2018[2025-10-31]. https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD201801&filename=1017075991.nh.<br>
[2] 弋凡. 基于FPGA的卷积神经网络加速器的设计与实现[D/OL]. 西安电子科技大学, 2020[2025-10-31]. https://doi.org/10.27389/d.cnki.gxadu.2019.002183.<br>
[3] 梅志伟. 卷积神经网络加速模块设计与FPGA实现[D/OL]. 浙江大学, 2021[2025-10-31]. https://doi.org/10.27461/d.cnki.gzjdx.2020.003351.<br>
[4] 王绍润. 神经网络算法的FPGA加速研究[D/OL]. 武汉大学, 2019[2025-10-31]. https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD201902&filename=1019903811.nh.<br>
[5] 王春林. 基于ZYNQ的卷积神经网络软硬件协同设计研究与实现[D/OL]. 大连海事大学, 2021[2025-10-31]. https://doi.org/10.26989/d.cnki.gdlhu.2020.001152.<br>
[6] 高存远. 基于FPGA的YOLOv3-Tiny算法的设计[D/OL]. 东南大学, 2022[2025-10-31]. https://doi.org/10.27014/d.cnki.gdnau.2020.003767.<br>
[7] 邹丹音. 基于深度学习的目标检测算法FPGA实现[D/OL]. 哈尔滨工业大学, 2020[2025-10-31]. https://doi.org/10.27061/d.cnki.ghgdu.2019.003779.<br>
[8] 张丽丽. 基于HLS的Tiny-yolo卷积神经网络加速研究[D/OL]. 重庆大学, 2018[2025-10-31]. https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD201801&filename=1017722649.nh.<br>
[9] 童耀宗. 基于FPGA的卷积神经网络加速器的设计与实现[D/OL]. 电子科技大学, 2019[2025-10-31]. https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD201902&filename=1019852444.nh.<br>
[10] 黄圳. 深度学习算法的FPGA硬件加速研究与实现[D/OL]. 电子科技大学, 2020[2025-10-31]. https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD202001&filename=1019851111.nh.<br>
[11] 龚豪杰. 基于FPGA的卷积神经网络加速方法研究与实现[D/OL]. 中国科学院大学（中国科学院国家空间科学中心）, 2022[2025-10-31]. https://doi.org/10.27562/d.cnki.gkyyz.2021.000053.<br>

#### 总结
**综合而言**
> 处于方便考虑,以下价格均仅来至于国内京东查询价格的大致情况,其他渠道没有调查
+ 对于搭载**zynq-7000家族的7020系列**最常被提及的是**ZedBoard (XC7Z020): Avnet 经典 Zynq 开发板**价格约为4000￥上下
+ 对于更高需求的的**Zynq UltraScale+ MPSoC**最常被提及的是**eg系列和ev系列的官方评估板套件**如  **ZCU102(XCZU9EG)与ZCU104(XCZU7EV)a**其中ZCU102搭载的是9EG系列芯片价格非常昂贵,价格约为2-3万元不等，而ZCU104为更加面向视频 AI的版本,带有集成硬件视频编解码单元 (VCU)价格比前者便宜不少,约为1.3-1.4万元
+ 在经济化的选择而言,**zynq-7000家族的7020系列**的**PYNQ-Z2**价格约为2000上下,**Zynq UltraScale+ MPSoC**家族的**Ultra96-V2**搭载的是3EG系列约为2800-3000元,而**KV260**也是基于3EG的开发板,但是提供了更加即用的硬件和软件堆栈，降低开发门槛,价格约为3500元不等,并且其价格收到是否为ED版本即教育折扣版影响,两者在硬件、性能和功能上完全相同，唯一的区别在于目标用户、定价和购买资格.